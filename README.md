# ğŸ“„ RAG ê¸°ë°˜ ê°€ìƒ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì±—ë´‡ (Streamlit + LangChain + FAISS)

ì´ í”„ë¡œì íŠ¸ëŠ” ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ **PDF/TXT í¬íŠ¸í´ë¦¬ì˜¤ ë¬¸ì„œ**ë¥¼ ë¶„ì„í•˜ì—¬  
í•´ë‹¹ ë¬¸ì„œ ê¸°ë°˜ì˜ **ê¸°ìˆ  ë©´ì ‘ ì§ˆë¬¸**ì„ ìƒì„±í•´ì£¼ëŠ” **RAG(Retrieval-Augmented Generation)** ê¸°ë°˜ ì±—ë´‡ì…ë‹ˆë‹¤.

OpenAI Embeddings + FAISS ë²¡í„°ìŠ¤í† ì–´ + LangChain + Streamlit ë¡œ êµ¬ì„±ë˜ë©°,  
ë¬¸ì„œë¥¼ ë²¡í„°í™” í›„ ì €ì¥í•˜ì—¬ ë‹¤ìŒ ì‹¤í–‰ ë•Œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- PDF/TXT ë¬¸ì„œ ì—…ë¡œë“œ í›„ ìë™ í…ìŠ¤íŠ¸ ì¶”ì¶œ  
- RecursiveCharacterTextSplitter ë¡œ ë¬¸ì„œ ì²­í¬ ë¶„í•   
- OpenAIEmbeddings ë¡œ ë¬¸ì„œ ì„ë² ë”© ìƒì„±  
- FAISS ë²¡í„°ìŠ¤í† ì–´ì— ì¸ë±ìŠ¤ ì €ì¥ ë° ë¡œë“œ  
- LangChain RAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±  
- Streamlit UI ì œê³µ  

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

.<br>
â”œâ”€â”€ app.py # Streamlit ì‹¤í–‰ ë©”ì¸ íŒŒì¼ <br>
â”œâ”€â”€ .env # OPENAI_API_KEY ì €ì¥<br>
â”œâ”€â”€ faiss_index/ # ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ í´ë” (ì‹¤í–‰ í›„ ìƒì„±ë¨)<br>
â””â”€â”€ README.md<br>

.env íŒŒì¼ ìƒì„±:

OPENAI_API_KEY=your_api_key_here

â–¶ï¸ ì‹¤í–‰ ë°©ë²•

Streamlit ì•± ì‹¤í–‰:

streamlit run virtual_interview.py

ë¸Œë¼ìš°ì €ì—ì„œ ìë™ ì‹¤í–‰ë©ë‹ˆë‹¤.

ğŸ§  ì‚¬ìš© ë°©ë²•
1. ë¬¸ì„œ ì—…ë¡œë“œ

PDF ë˜ëŠ” TXT íŒŒì¼ ì—…ë¡œë“œ

ë¬¸ì„œ ë¶„í•  â†’ ì„ë² ë”© ìƒì„± â†’ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ìë™ ìˆ˜í–‰

2. ë²¡í„°ìŠ¤í† ì–´ ìë™ ë¡œë“œ

faiss_index/ í´ë”ê°€ ìˆìœ¼ë©´ ìë™ ë¡œë“œ

ë¬¸ì„œ ì¬ì—…ë¡œë“œ ë¶ˆí•„ìš”

3. ì§ˆë¬¸ ìƒì„±

ë²„íŠ¼ í´ë¦­ â†’ ë¬¸ì„œ ê¸°ë°˜ ê¸°ìˆ  ë©´ì ‘ ì§ˆë¬¸ ìë™ ìƒì„±

ğŸ” RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¡°
User Question
        â”‚
        â–¼
Retriever (FAISS)
        â”‚
        â–¼
Context + Prompt êµ¬ì„±
        â”‚
        â–¼
ChatOpenAI (LLM)
        â”‚
        â–¼
ë©´ì ‘ ì§ˆë¬¸ ìƒì„±

ğŸ“Œ ì£¼ìš” ì½”ë“œ ì„¤ëª…
ë¬¸ì„œ ë¡œë“œ & ë¶„í• 
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100
)
docs = splitter.split_documents(documents)

ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
embeddings = OpenAIEmbeddings()
vectordb = FAISS.from_documents(docs, embeddings)
vectordb.save_local("faiss_index")

ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

RAG ì²´ì¸ êµ¬ì„±
rag_chain = (
    {
        "context": retriever,
        "question": RunnableLambda(lambda x: x["question"])
    }
    | prompt
    | llm
)
